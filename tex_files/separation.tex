\section{Separation Under Verifiable DP}
\label{sec:separation}

We show that information theoretic verifiable DP is impossible in the trusted curator model.
To prove our result stated in Theorem~\ref{theorem:coms_imply_vdp}, we rely on the impossibility of secure coin flipping by \cite{haitner2014coin}.


\begin{thm}[Impossibility Of Tossing A Fair Coin]\cite{haitner2014coin}  \label{theorem:coin_flip_implies_one_way_functions} 
Let $(\Prover, \Verifier)$ be a coin tossing protocol and let $B_\lambda = \mathbb{E}[\texttt{out}(\Prover, \Verifier)(1^\SecurityParam)]$ be the bias of the output of such a protocol. 
Assuming that one-way-functions do not exist, then for any $g \in \poly(\SecurityParam)$, 
there exists a pair of efficient cheating strategies $\ChProver$ and $\ChVerifier$ such that the following holds:
for infinitely many $\SecurityParam$'s, for each $j \in \bit$ either $\Pr[\texttt{out}(\ChProver , \Verifier)(1^\SecurityParam) = j]$ or $\Pr[\texttt{out}(\Prover, \ChVerifier)(1^\SecurityParam)= j]$ is greater than $\sqrt{B_\SecurityParam^j} - \frac{1}{g(\SecurityParam)}$, where $B_\SecurityParam^1 = B_\lambda$ and $B_\SecurityParam^0 = 1 - B_\lambda$. In particular for $B_\lambda=\frac{1}{2}$, the corrupted party can bias the outcome by almost $\frac{1}{\sqrt{2}} - \frac{1}{2}$.
\end{thm}

The theorem above states that it is impossible for two unbounded parties to jointly sample an unbiased public coin. The result is stronger than the impossibility result by Cleve \cite{cleve1986limits}, which states that it is impossible to jointly flip an unbiased coin if we allow parties to exit early. 
The theorem above states that it is impossible even if we guarantee no party exists the protocol early.

\begin{thm}[Information Theoretic Verifiable DP is impossible]  
\label{theorem:coms_imply_vdp}  
Any constant round interactive protocols $\Pi$ for an DP-mechanism $\mathcal{M}_\bin$ that satisfies Verifiable-DP (Definition \ref{defn:vdp_MPC}) cannot have unconditional soundness and statistical zero knowledge.
\end{thm}

\begin{proof}
%
% Consider any additive DP mechanism $\mathcal{M}(X, Q, \vec{r}) = Q(X) + f(\vec{r})$,  where $\vec{r} \in \bit^{\texttt{poly}(\SecurityParam)}$ is the randomness used to guarantee DP.  
% Assume there exists a constant round verifiable DP proof $\Pi$ for $\mathcal{M}$ with unconditional soundness and statistical zero knowledge.
% As we assume that both the prover and the verifier are unbounded, functions with one-way instances cannot exist (Definition \ref{defn:one_way_instances}).
% %
% Let $y = \mathcal{M}(X, Q, \vec{r})$ and define the language $L_y$ such that
% \begin{equation}
% L_y = \{ \vec{r}:  y = \mathcal{M}(X, Q, \vec{r})\}	
% \end{equation}

% Given $y=\mathcal{M}(X, Q, \vec{r})$ and $y' = \mathcal{M}(X', Q, \vec{r})$, the task of extracting $\vec{r}$ to check whether $\vec{r} \in L_y$ is clearly not in $\mathcal{BPP}$. 
% If an efficient PPT algorithm could find $\vec{r}$ from $y$ and $y'$, then it could distinguish between the DP outputs of two neighboring datasets (by simply inspecting $y - f(\vec{r})$ and $y' - f(\vec{r})$), which we know by definition of DP (Definition~\ref{def:dp_definitions}) is impossible. In fact information theoretic DP claims that even an unbounded algorithm is unable to extract $\vec{r}$.
% By our assumption, there was an unconditionally sound zero knowledge proof for $L_y$ by which an unbounded verifying algorithm could learn nothing beyond the answer that $\vec{r} \in L_y$. Therefore by Theorem \ref{theorem:hard_one_way_exists}, functions with one-way-instances must exist which is a contradiction.
Verifiable DP requires that a verifier be able to guarantee that the randomness generated by a prover remains unbiased, without the verifier ever seeing the randomness. Theorem \ref{theorem:coin_flip_implies_one_way_functions}, states that it is impossible for two unbounded parties to even jointly sample a \textit{public} unbiased coin without assuming one way functions. 
Thus commitment schemes are both necessary and sufficient to jointly sample an unbiased public coin. \par
The task of jointly sampling unbiased \textit{private} randomness is harder. If two parties could sample unbiased private randomness, then they could just use the same protocol to sample unbiased public randomness, by revealing the randomness.
Thus, commitment schemes are a necessary condition for verifiable DP.
Commitments cannot be both statistically binding and hiding, thus unbounded soundness and statistical zero knowledge is impossible.
\end{proof}



\paragraph{Connection With Open Problem}
%
\begin{definition}[$\alpha$-useful mechanism]
  \label{defn:utility} Fix $\alpha \in [0,1]$. Let $u : \mathcal{X}^n \times \mathcal{Y} \rightarrow \in \bit$  be an efficiently computable deterministic function. A mechanism $\mathcal{M}$ is $\alpha$-useful for a utility function $u$ if for some $Q \in \mathcal{Q}$ and for all $X \in \mathcal{X}^n$
 % 
  \begin{equation}
  \Pr_{y \leftarrow \mathcal{M}(X, Q)}[u(X, y) = 1] \geq \alpha  
  \end{equation}
  \end{definition}

In his survey on the complexity of DP, Vadhan \cite{vadhan2017complexity} asks the following question. Given $X \in \mathcal{X}^n$ and a differentially private mechanism $\mathcal{M}: \mathcal{X}^n \times \mathcal{Q} \rightarrow \mathcal{Y}$, is there an efficient utility function $u$ that is $\alpha$-useful when $\mathcal{M}$ is IND-CDP but not when $\mathcal{M}$ is information-theoretically DP. 
Groce \etal \cite{groce2011limits} show that if the range of $u$ is in $\mathcal{R}^n$ and the utility is measured in terms of the $\mathcal{L}_p$-norm, then statistical-DP and computational DP are equivalent. Thus for the separation to hold, the range of $u$ must have a more complex structure, such as a graph, a circuit or a proof. 
Bun \etal corroborate this result by describing a utility function such that $u$ is infeasible (not impossible) when $\mathcal{M}$ is statistical DP and efficient when $\mathcal{M}$ is computational DP~\cite{bun2016separating}. 
Similar to our definition of verifiability, their utility function $u$ is cryptographic and unnatural from a data analysis point of view. Specifically, given $y = \mathcal{M}(X, Q)$, Bun \etal define the utility as the answer to the question of whether $y$ is a valid zap proof \cite{dwork2000zaps} of the statement ``there exists a row in $X$ that is a valid message signature pair''. 
 Meanwhile, we define our utility function as an interactive proof that checks whether the real protocol output $y$ is indistinguishable from the output of an ideal run of $\mathcal{M}$. 
 In Theorem \ref{theorem:coms_imply_vdp}, we show that verifiable DP is impossible in the presence of computationally unbounded adversaries. 
This provides a candidate for a separation between statistical DP and computational DP.
 
 However, there are some key differences between our formulation of utility and how it was originally posed.
 For example, in Bun \etal, the utility function $u$ is a deterministic non-interactive function that receives the output $y$ and a dataset $X$ of message-signature pairs. The task of evaluating utility is separate from the task of computing DP statistics.
 In verifiable DP, both the DP statistic and utility are computed simultaneously via a constant round interactive protocol. 
 Furthermore, the number of rounds of the utility function is a function of the privacy parameter $\epsilon$. 
 Another point of difference is that, in verifiable DP, the verifier performs the dual role of evaluating the utility of the mechanism and generating randomness that prevents a curator from cheating (although it does not ever see this randomness). In Bun \etal, the verifier's task is just to verify the proof. 
 They are not involved in generating the DP noise.
 Although we show that information theoretic verifiable DP is impossible, our definitions allow the adversary more agency. Thus the two settings are not directly comparable. 
 We defer finding stronger connections between verifiable DP and finding a utility function that separates DP as per  \cite{vadhan2017complexity} to future work.
